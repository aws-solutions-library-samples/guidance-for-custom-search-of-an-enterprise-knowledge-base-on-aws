{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d5cbc5-018d-4b1b-80ea-2f6f68994c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"./python\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "import traceback\n",
    "import urllib.parse\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import time\n",
    "from opensearch_vector_search import OpenSearchVectorSearch\n",
    "from langchain.embeddings.sagemaker_endpoint import EmbeddingsContentHandler\n",
    "from langchain.embeddings.sagemaker_endpoint import SagemakerEndpointEmbeddings\n",
    "from model import *\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108d3672-aff9-417c-9299-af1fb9e712ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据时间情况修改index和language值\n",
    "\n",
    "index =  \"\"\n",
    "language = \"english\"\n",
    "embedding_endpoint_name = \"cohere.embed-multilingual-v3\"\n",
    "\n",
    "port = 443\n",
    "bulk_size = 10000000\n",
    "\n",
    "sm_client = boto3.client('secretsmanager')\n",
    "master_user = sm_client.get_secret_value(SecretId='opensearch-host-url')['SecretString']\n",
    "data= json.loads(master_user)\n",
    "es_host_name = data.get('host')\n",
    "host = es_host_name+'/' if es_host_name[-1] != '/' else es_host_name# cluster endpoint, for example: my-test-domain.us-east-1.es.amazonaws.com/\n",
    "host = host[8:-1]\n",
    "region = boto3.Session().region_name # e.g. cn-north-1\n",
    "print('host:',host)\n",
    "print('region:',region)\n",
    "\n",
    "# retrieve secret manager value by key using boto3                                             \n",
    "sm_client = boto3.client('secretsmanager')\n",
    "master_user = sm_client.get_secret_value(SecretId='opensearch-master-user')['SecretString']\n",
    "data= json.loads(master_user)\n",
    "username = data.get('username')\n",
    "password = data.get('password')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7badb9-078e-4f40-a160-d3db2b84ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_type = 'bedrock' if embedding_endpoint_name.find('titan') or embedding_endpoint_name.find('cohere') else 'sagemaker'\n",
    "embeddings = init_embeddings_bedrock(embedding_endpoint_name)\n",
    "vector_store=init_vector_store(embeddings,index,host,port,username,password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75602f5-6e3d-4556-b55a-46e46788a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"./python\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "import fitz\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import base64\n",
    "from model import init_model_bedrock\n",
    "\n",
    "model_name = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "llm = init_model_bedrock(model_name)\n",
    "text_max_length = 2000\n",
    "\n",
    "def is_json(myjson):\n",
    "    try:\n",
    "        json.loads(myjson)\n",
    "    except ValueError as e:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are a document organizer of bicycle company and your task is to extract useful information from images.Please refer to the format of the content of the previous page to extract text information from the image on the current page.\n",
    "If the content on this page contains tables or maintenance process, please organize the tables or maintenance process into json format. \n",
    "If the content of this page is a table and has no header, use the header of the previous page. \n",
    "If the content of this page is a maintenance process and does not specify the specific maintenance object, use the maintenance object on the previous page.\n",
    "\n",
    "<previous page content>\n",
    "{context}\n",
    "</previous page content>\n",
    "No preface, just output the content directly.\n",
    "\"\"\"\n",
    "\n",
    "files_path = '../../docs/giant/'\n",
    "os.mkdir('images/')\n",
    "files = os.listdir(files_path)\n",
    "for file in files:\n",
    "    file_path = files_path + file\n",
    "    print(file_path)\n",
    "    fname = file.split('/')[-1].split('.')[0]\n",
    "    print(fname)\n",
    "    os.mkdir('images/'+fname)\n",
    "\n",
    "    doc = fitz.open(file_path)\n",
    "    previous_page_content = ''\n",
    "\n",
    "    for i in tqdm(range(doc.page_count)):\n",
    "        if i < 2:\n",
    "            continue\n",
    "        texts = []\n",
    "        metadatas = []\n",
    "        page = doc.load_page(i)\n",
    "        pix = page.get_pixmap()\n",
    "        \n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        img_name = fname + '-' + str(i) + '.jpg'\n",
    "        img.save('images/'+fname + '/' + img_name, \"JPEG\")\n",
    "        \n",
    "        imgb64 = base64.b64encode(pix.tobytes()).decode(\"utf-8\")\n",
    "        model_kwargs = {'image': imgb64,'max_tokens':2048}\n",
    "        llm.model_kwargs = model_kwargs\n",
    "        new_prompt = prompt.format(context=previous_page_content)\n",
    "        response = llm(prompt=new_prompt)\n",
    "        response = response.strip()\n",
    "        previous_page_content = response\n",
    "        \n",
    "        # print('response:',response)\n",
    "        response_set = set()\n",
    "        if is_json(response) and response.find('{') >=0:\n",
    "            response = json.loads(response)\n",
    "            for data in response:\n",
    "                if isinstance(response[data], dict):\n",
    "                    for sub_key in response[data]:\n",
    "                        text = str(sub_key) + '\\n' + str(response[data][sub_key])\n",
    "                        response_set.add(text)\n",
    "                else:\n",
    "                    text = str(data) + '\\n' + str(response[data])\n",
    "                    response_set.add(text)\n",
    "            response = json.dumps(response)\n",
    "        else:\n",
    "            response_list = response.split('\\n')\n",
    "            for data in response_list:\n",
    "                data = data.strip().replace('null','')\n",
    "                if len(data) > 2:\n",
    "                    if is_json(data) and data.find('{') >=0:\n",
    "                        data = json.loads(data)\n",
    "                        for sub_key in data:\n",
    "                            text = str(sub_key) + '\\n' + str(data[sub_key])\n",
    "                            response_set.add(text)\n",
    "                    else:\n",
    "                        response_set.add(data)\n",
    "        for text in response_set:\n",
    "            texts.append(str(response).replace(': null,',''))\n",
    "            metadata = {}\n",
    "            metadata['sentence'] = text[:text_max_length] if len(text) > text_max_length else text\n",
    "            metadata['sources'] = file.split('/')[-1]\n",
    "            metadata['type'] = 'pdf'\n",
    "            metadata['page'] = i\n",
    "            metadata['image'] = img_name\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "        print('texts len:',len(texts))\n",
    "        print('metadatas len:',len(metadatas))\n",
    "        print('begin to save in vectore store')\n",
    "        vector_store.add_texts_sentence_in_metadata(\n",
    "            texts=texts,\n",
    "            metadatas=metadatas,\n",
    "            bulk_size=10000,\n",
    "            batch_size=100,\n",
    "            text_field='paragraph',\n",
    "            vector_field='sentence_vector',\n",
    "            embedding_type=embedding_type\n",
    "        )\n",
    "        print('finish save in vectore store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a1ec13-faa9-4bc7-81aa-9e6ae8f0baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Just for srt file data load\n",
    "\n",
    "import pysrt\n",
    "import os\n",
    "\n",
    "source_map={\n",
    "'Script - SXC 32 Fork Remote Lockout Service [2023_SM_INC].srt':'SXC 32 Fork Remote Lockout Service [2023_SM_INC].mp4',\n",
    "'subtitle_Contact Switch Dropper Seatpost Service [2023_SM_INC].srt':'Contact Switch Dropper Seatpost Service [2023_SM_INC]-selected.mp4',\n",
    "'Crest Fork Series Differentiation [2022_SM_INC].srt':'Crest Fork Series Differentiation [2022_SM_INC].mp4',\n",
    "'Script - STL 34 Fork Air Spring Service [2023_SM_INC].srt':'STL 34 Fork Air Spring Service [2023_SM_INC].mp4',\n",
    "'subtitles_Contact Switch AT Dropper - Dropper Seatpost Service [2024_SM_INC].srt':'final_Contact Switch AT Dropper - Dropper Seatpost Service [2024_SM_INC].mp4',\n",
    "'Script - Contact Aerolight Stem Range Introduction.srt':'Contact Aerolight Stem/ Range Introduction [2023_SM_INC].mp4',\n",
    "'Script - SXC 32 Fork Air Spring Service [2023_SM_INC].srt':'SXC 32 Fork Air Spring Service [2023_SM_INC].mp4',\n",
    "'CREST 34 SL Lower Leg Service [2022_SM_INC].srt':'CREST 34 SL Lower Leg Service [2022_SM_INC].mp4',\n",
    "'subtitles_Contact Switch AT Dropper - Remote Lever Installation [2024_SM_INC].srt':'final_Contact Switch AT Dropper - Remote Lever Installation [2024_SM_INC].mp4',\n",
    "'CREST 34 SL Damper Service [2022_SM_INC].srt':'CREST 34 SL Damper Service [2022_SM_INC].mp4'\n",
    "}\n",
    "\n",
    "def time_to_num(time_str):\n",
    "    hh, mm , ss = map(int, time_str.split(':'))\n",
    "    return ss + 60*(mm + 60*hh)\n",
    "\n",
    "srt_path = '../docs/giant_srt/'\n",
    "files = os.listdir(srt_path)\n",
    "texts = []\n",
    "metadatas = []\n",
    "for file in files:\n",
    "    print(file)\n",
    "    if file.find('checkpoints') >=0:\n",
    "        continue\n",
    "    video_name = source_map[file]\n",
    "    subs = pysrt.open(srt_path + file)\n",
    "    for sub in subs:\n",
    "        text = sub.text\n",
    "        texts.append(text)\n",
    "        start = sub.start.to_time()\n",
    "        hour = start.hour\n",
    "        minute = start.minute\n",
    "        second = start.second\n",
    "        metadata = {}\n",
    "        metadata['type'] = 'video'\n",
    "        metadata['start'] = second + 60*minute + 3600*hour\n",
    "        metadata['source'] = video_name\n",
    "        metadata['sentence'] = text\n",
    "        metadatas.append(metadata)\n",
    "print(len(texts))\n",
    "print(len(metadatas))\n",
    "\n",
    "print('begin to save in vectore store')\n",
    "vector_store.add_texts_sentence_in_metadata(\n",
    "    texts=texts,\n",
    "    metadatas=metadatas,\n",
    "    bulk_size=10000,\n",
    "    batch_size=100,\n",
    "    text_field='paragraph',\n",
    "    vector_field='sentence_vector',\n",
    "    embedding_type=embedding_type\n",
    ")\n",
    "print('finish save in vectore store')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
