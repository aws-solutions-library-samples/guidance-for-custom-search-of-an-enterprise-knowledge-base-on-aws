{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0241f04f-873e-4e22-bb59-57ee7abbd596",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade numpy --target ./python\n",
    "!pip install --upgrade numexpr --target ./python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b44f39c2-1b3c-40b1-a1a0-9239ab65316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"./python\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "from model import *\n",
    "\n",
    "#根据时间情况修改index和language值\n",
    "index =  \"\"\n",
    "language = \"english\"\n",
    "embedding_endpoint_name = \"cohere.embed-multilingual-v3\"\n",
    "\n",
    "embedding_type = 'bedrock' if embedding_endpoint_name.find('titan') or embedding_endpoint_name.find('cohere') else 'sagemaker'\n",
    "embeddings = init_embeddings_bedrock(embedding_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f25c55-868a-483b-ad3e-329ab2d57906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"./python\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "import fitz\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import base64\n",
    "from opensearch_multimodel_dataload import add_multimodel_documents\n",
    "\n",
    "model_name = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "llm = init_model_bedrock(model_name)\n",
    "text_max_length = 2000\n",
    "\n",
    "def is_json(myjson):\n",
    "    try:\n",
    "        json.loads(myjson)\n",
    "    except ValueError as e:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are a document organizer of manufacture company and your task is to extract useful information from images.Please refer to the format of the content of the previous page to extract text information from the image on the current page.\n",
    "If the content on this page contains tables or maintenance process, please organize the tables or maintenance process into json format. \n",
    "If the content of this page is a table and has no header, use the header of the previous page. \n",
    "If the content of this page is a maintenance process and does not specify the specific maintenance object, use the maintenance object on the previous page.\n",
    "\n",
    "<previous page content>\n",
    "{context}\n",
    "</previous page content>\n",
    "No preface, just output the content directly.\n",
    "\"\"\"\n",
    "\n",
    "files_path = '../docs/giant/'\n",
    "# os.mkdir('images/')\n",
    "files = os.listdir(files_path)\n",
    "for file in files:\n",
    "    file_path = files_path + file\n",
    "    print(file_path)\n",
    "    # fname = file.split('/')[-1].split('.')[0]\n",
    "    # print(fname)\n",
    "    # os.mkdir('images/'+fname)\n",
    "\n",
    "    doc = fitz.open(file_path)\n",
    "    previous_page_content = ''\n",
    "    \n",
    "    texts = []\n",
    "    metadatas = []\n",
    "    images = []\n",
    "    \n",
    "    for i in tqdm(range(doc.page_count)):\n",
    "        if i < 2:\n",
    "            continue\n",
    "            \n",
    "        page = doc.load_page(i)\n",
    "        pix = page.get_pixmap()\n",
    "        \n",
    "        # img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        # img_name = fname + '-' + str(i) + '.jpg'\n",
    "        # img.save('images/'+fname + '/' + img_name, \"JPEG\")\n",
    "        \n",
    "        imgb64 = base64.b64encode(pix.tobytes()).decode(\"utf-8\")\n",
    "        model_kwargs = {'image': imgb64,'max_tokens':2048}\n",
    "        llm.model_kwargs = model_kwargs\n",
    "        new_prompt = prompt.format(context=previous_page_content)\n",
    "        response = llm(prompt=new_prompt)\n",
    "        response = response.strip()\n",
    "        previous_page_content = response\n",
    "        \n",
    "        print('response:',response)\n",
    "        response_set = set()\n",
    "        if is_json(response) and response.find('{') >=0:\n",
    "            response = json.loads(response)\n",
    "            for data in response:\n",
    "                if isinstance(response[data], dict):\n",
    "                    for sub_key in response[data]:\n",
    "                        text = str(sub_key) + '\\n' + str(response[data][sub_key])\n",
    "                        response_set.add(text)\n",
    "                else:\n",
    "                    text = str(data) + '\\n' + str(response[data])\n",
    "                    response_set.add(text)\n",
    "            response = json.dumps(response)\n",
    "        else:\n",
    "            response_list = response.split('\\n')\n",
    "            for data in response_list:\n",
    "                data = data.strip().replace('null','')\n",
    "                if len(data) > 2:\n",
    "                    if is_json(data) and data.find('{') >=0:\n",
    "                        data = json.loads(data)\n",
    "                        for sub_key in data:\n",
    "                            text = str(sub_key) + '\\n' + str(data[sub_key])\n",
    "                            response_set.add(text)\n",
    "                    else:\n",
    "                        response_set.add(data)\n",
    "        for text in response_set:\n",
    "            texts.append(str(response).replace(': null,',''))\n",
    "            images.append(imgb64)\n",
    "            metadata = {}\n",
    "            metadata['sentence'] = text[:text_max_length] if len(text) > text_max_length else text\n",
    "            metadata['sources'] = file.split('/')[-1]\n",
    "            metadata['page'] = i\n",
    "            metadatas.append(metadata)\n",
    "    if len(texts) > 0:\n",
    "        if embedding_type == 'bedrock':\n",
    "            text_embeddings = embeddings.embed_documents(list([metadata[\"sentence\"] for metadata in metadatas]))\n",
    "        else:\n",
    "            text_embeddings = embeddings.embed_documents(list([metadata[\"sentence\"] for metadata in metadatas]),chunk_size=10)\n",
    "\n",
    "        print('texts len:',len(texts))\n",
    "        print('metadatas len:',len(metadatas))\n",
    "        print('embeddings len:',len(text_embeddings))\n",
    "        print('images len:',len(images))\n",
    "        print('begin to save in vectore store')\n",
    "\n",
    "        add_multimodel_documents(\n",
    "            index,\n",
    "            texts=texts,\n",
    "            embeddings=text_embeddings,\n",
    "            metadatas=metadatas,\n",
    "            images=images\n",
    "        )\n",
    "        print('finish save in vectore store')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
