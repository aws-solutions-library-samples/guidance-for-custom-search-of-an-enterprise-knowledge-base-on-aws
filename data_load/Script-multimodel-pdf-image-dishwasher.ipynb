{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a9d4e5-4815-4eb1-ba42-6af78d658208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install PyPDF2\n",
    "!pip install pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ec7773-cad9-48f3-9a69-3962fbe544c5",
   "metadata": {},
   "source": [
    "##  HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dddbfa8-aae1-4326-b6e2-d8fe52052409",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##  HyperParameters\n",
    "\n",
    "# The name of index\n",
    "index_name = 'dishwasher'\n",
    "\n",
    "# The name of embbeding model endpoint\n",
    "eb_endpoint = ''\n",
    "\n",
    "# Ebbeding vector dimension, usually you can keep it as default\n",
    "v_dimension = 1024\n",
    "\n",
    "# Docs file folder to be processed and ingested\n",
    "folder_path = '../docs/dishwasher/'\n",
    "\n",
    "# The imported data of the same index_name, usually you can keep it as 0 if you are creating a new index\n",
    "before_import = 0\n",
    "\n",
    "# # The number of pages for one chunk\n",
    "# # It should note that the token of one chunk should smaller than the maximum input token of embedding model\n",
    "# num_chunk_for_one_paragraph = 7\n",
    "\n",
    "# The resolution of PDF\n",
    "resolution = 1.0\n",
    "\n",
    "# The number of overlap pages between chunk\n",
    "overlap_pages = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78511340-ba54-4487-a7ce-73e85951172b",
   "metadata": {},
   "source": [
    "## Function Defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca786f2-d380-4121-a941-5de7fcf16183",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fitz\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def pdf_to_base64_images(pdf_file_path, img_dir='test_img', show_imgs=False):\n",
    "    # 打开PDF文件\n",
    "    pdf_file = fitz.open(pdf_file_path)\n",
    "\n",
    "    # 创建一个列表来存储每页的base64编码\n",
    "    base64_images = []\n",
    "\n",
    "    # 循环遍历每一页\n",
    "    for page_index in range(len(pdf_file)):\n",
    "        # 选择一个页面\n",
    "        page = pdf_file[page_index]\n",
    "        # 获取页面的尺寸\n",
    "        image_width, image_height = page.rect.width, page.rect.height\n",
    "        # 将页面渲染为一个PIL图像\n",
    "        mat = fitz.Matrix(resolution, resolution)\n",
    "        pix = page.get_pixmap(matrix=mat)\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        \n",
    "        if show_imgs:\n",
    "        # 将 PIL Image 对象转换为 NumPy 数组\n",
    "            img_np = np.asarray(img)\n",
    "\n",
    "            # 使用 matplotlib 显示图像\n",
    "            plt.imshow(img_np)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        # 将PIL图像转换为字节流\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        img.save(img_byte_arr, format='PNG')\n",
    "        img_byte_arr = img_byte_arr.getvalue()\n",
    "\n",
    "        # 将字节流编码为base64\n",
    "        base64_image = base64.b64encode(img_byte_arr).decode('utf-8')\n",
    "        base64_images.append(base64_image)\n",
    "        \n",
    "        #  # 将图像保存为文件\n",
    "        # img_file_path = os.path.join(img_dir, f'page_{page_index}.png')\n",
    "        # img.save(img_file_path, 'PNG')\n",
    "\n",
    "    return base64_images\n",
    "\n",
    "# 使用示例\n",
    "# pdf_file_path = \"docs/quectel/kb-faq/Wi-Fi_BT模块支持情况.pdf\"\n",
    "# xx = pdf_to_base64_images(pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c902334-cdc8-485d-837f-958bb1712dab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import boto3\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "import time\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "hfp = sagemaker.huggingface.model.HuggingFacePredictor(eb_endpoint)\n",
    "\n",
    "bedrock_runtime = boto3.client(service_name='bedrock-runtime')\n",
    "MODEL_ID = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "# MODEL_ID = 'anthropic.claude-3-haiku-20240307-v1:0'\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a document organizer of bicycle company and your task is to extract useful information from images.Please refer to the format of the content of the previous page to extract text information from the image on the current page.\n",
    "If the content on this page contains tables or maintenance process, please organize the tables or maintenance process into json format. \n",
    "If the content of this page is a table and has no header, use the header of the previous page. \n",
    "If the content of this page is a maintenance process and does not specify the specific maintenance object, use the maintenance object on the previous page.\n",
    "\n",
    "<previous page content>\n",
    "{context}\n",
    "</previous page content>\n",
    "No preface, just output the content directly.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def run_multi_modal_prompt(bedrock_runtime, model_id, messages, max_tokens, system_prompt=None):\n",
    "    \"\"\"\n",
    "    Invokes a model with a multimodal prompt.\n",
    "    Args:\n",
    "        bedrock_runtime: The Amazon Bedrock boto3 client.\n",
    "        model_id (str): The model ID to use.\n",
    "        messages (JSON) : The messages to send to the model.\n",
    "        max_tokens (int) : The maximum  number of tokens to generate.\n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    \n",
    "    sp = 'You are AI assistant'\n",
    "    if system_prompt is not None:\n",
    "        sp = system_prompt\n",
    "\n",
    "\n",
    "    body = json.dumps(\n",
    "        {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"system\": sp,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": 0.01,\n",
    "            \"stop_sequences\": [\"</output>\"]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    t0 = time.time()\n",
    "    # print('8*******************',t0)\n",
    "    response = bedrock_runtime.invoke_model(body=body, modelId=model_id)\n",
    "    # print(response)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    \n",
    "    t1 = time.time()\n",
    "    print(\"Invoke Cost: \",t1-t0)\n",
    "\n",
    "    return response_body\n",
    "\n",
    "\n",
    "\n",
    "def Sonnet(input_text, input_image_paths=None, input_images=None, max_tokens=4000, system_prompt='你是一个图片阅读助手，请尽可能用中文详细得描述图片中的内容', model_id=MODEL_ID):\n",
    "    \"\"\"\n",
    "    input_text: 输入的prompt\n",
    "    input_image_paths & input_images: 图像的输入为list，输入为一组图像地址input_image_paths或者base64编码后的图像input_images，优先input_image_paths\n",
    "    \"\"\"\n",
    "\n",
    "    # try:\n",
    "    content_images = []\n",
    "    if input_image_paths is not None:\n",
    "        # content_images = []\n",
    "\n",
    "        if Path(input_image_paths).is_file():\n",
    "            with open(input_image_paths, \"rb\") as image_file:\n",
    "                content_images.append(base64.b64encode(image_file.read()).decode('utf8'))\n",
    "        elif Path(input_image_paths).is_dir():\n",
    "            for input_image_path in input_image_paths:\n",
    "                with open(input_image_path, \"rb\") as image_file:\n",
    "                    content_images.append(base64.b64encode(image_file.read()).decode('utf8'))\n",
    "    elif input_images is not None:\n",
    "        content_images = input_images\n",
    "\n",
    "    content = [\n",
    "        {\n",
    "            \"type\": \"image\",\n",
    "            \"source\":\n",
    "            {\n",
    "                \"type\": \"base64\",\n",
    "                \"media_type\": \"image/jpeg\", \n",
    "                \"data\": content_image\n",
    "            }\n",
    "        }\n",
    "\n",
    "        for content_image in content_images\n",
    "    ]\n",
    "\n",
    "    content.append({\"type\": \"text\", \"text\": input_text})\n",
    "\n",
    "    # print(content)\n",
    "    message = {\"role\": \"user\",\n",
    "               \"content\": content}\n",
    "\n",
    "    messages = [message]\n",
    "    # print(messages)\n",
    "\n",
    "    response = run_multi_modal_prompt(\n",
    "        bedrock_runtime, model_id, messages, max_tokens, system_prompt)\n",
    "    # print(response, type(response))\n",
    "    # print(json.dumps(response, indent=4))\n",
    "    return response['content'][0]['text'].replace('<output>','')\n",
    "\n",
    "def get_title(path):\n",
    "    title = os.path.split(os.path.splitext(path)[0])[1]\n",
    "    return title\n",
    "\n",
    "\n",
    "def read_doc(path):\n",
    "    pages = pdf_to_base64_images(path)\n",
    "    sentence = []\n",
    "    sentence_r = []\n",
    "    imgbase64 = []\n",
    "    tmp_md = ''\n",
    "    for i in tqdm(range(len(pages))):\n",
    "        # try:\n",
    "        tmp_pages = pages[i]\n",
    "        tmp_md = Sonnet(input_text='<previous page content>'+tmp_md+'</previous page content>', \n",
    "                        input_image_paths=None, \n",
    "                        input_images=[tmp_pages], \n",
    "                        max_tokens=4096, \n",
    "                        system_prompt=system_prompt, \n",
    "                        model_id=MODEL_ID)\n",
    "        print(tmp_md)\n",
    "        sentence.append(tmp_md)\n",
    "        imgbase64.append(tmp_pages)\n",
    "        sentence_r.append(tmp_md)\n",
    "        \n",
    "    df = pd.DataFrame({\n",
    "        'title':[get_title(path) for i in range(len(sentence))],\n",
    "        'paragraph': sentence,\n",
    "        'sentence': sentence,\n",
    "        'image_base64': imgbase64\n",
    "    })\n",
    "    return df, sentence_r\n",
    "\n",
    "def get_vector(input_text):\n",
    "    try:\n",
    "        return hfp.predict({'inputs':[input_text]})[0]\n",
    "    except:\n",
    "        print(\"embedding failed\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def embbeding(df):\n",
    "    df['sentence_vector'] = ''\n",
    "    title_vector = str(get_vector(df.iloc[0, 0]))\n",
    "    for i in range(len(df)):\n",
    "        df.iloc[i, 4] = str(get_vector(df.iloc[i, 2]))\n",
    "        print('\\r embbeding %i out of %i finished'%(i, len(df)), end='')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374d6fba-f517-4c99-b74e-ea71116e90d7",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85040f59-8b93-4e9c-9e72-4c5529145ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create index\n",
    "\n",
    "import requests\n",
    "\n",
    "# ==============OpenSearch Related=====================\n",
    "# retrieve secret manager value by key using boto3\n",
    "sm_client = boto3.client('secretsmanager')\n",
    "master_user = sm_client.get_secret_value(SecretId='opensearch-host-url')['SecretString']\n",
    "data= json.loads(master_user)\n",
    "es_host_name = data.get('host')\n",
    "host = es_host_name+'/' if es_host_name[-1] != '/' else es_host_name# cluster endpoint, for example: my-test-domain.us-east-1.es.amazonaws.com/\n",
    "region = boto3.Session().region_name # e.g. cn-north-1\n",
    "# sm_client = boto3.client('secretsmanager')\n",
    "master_user = sm_client.get_secret_value(SecretId='opensearch-master-user')['SecretString']\n",
    "data= json.loads(master_user)\n",
    "username = data.get('username')\n",
    "password = data.get('password')\n",
    "# service = 'es'\n",
    "# credentials = boto3.Session().get_credentials()\n",
    "awsauth = (username, password)\n",
    "url = host+'_bulk'\n",
    "headers = { \"Content-Type\": \"application/json\" }\n",
    "\n",
    "payloads = {\n",
    "\"settings\": { \"index\": {\n",
    "\"knn\": True,\n",
    "\"knn.algo_param.ef_search\": 100 }\n",
    "}, \"mappings\": {\n",
    "\"properties\": { \n",
    "\"sentence_vector\": {\n",
    "\"type\": \"knn_vector\", \"dimension\": v_dimension, \"method\": {\n",
    "\"name\": \"hnsw\", \"space_type\": \"l2\", \"engine\": \"nmslib\", \"parameters\": {\n",
    "\"ef_construction\": 256,\n",
    "\"m\": 128 }\n",
    "} },\n",
    "\"sentence\": {\"type\": \"text\" }, \n",
    "\"paragraph\": {\"type\": \"text\" }, \n",
    "\"image_base64\": {\"type\": \"text\"},\n",
    "\"metadata\": {\n",
    "    \"properties\":{\n",
    "\"page\": {\"type\": \"long\"},\n",
    "\"source\": {\"type\": \"text\"},\n",
    "}}\n",
    "} }\n",
    "}\n",
    "\n",
    "# Create Index\n",
    "r = requests.put(host+index_name, auth=awsauth, headers=headers, json=payloads)\n",
    "print(r.text)\n",
    "\n",
    "def import_data(df, id_start=0, before_import=0):\n",
    "    payloads = ''\n",
    "    for i in range(id_start, len(df)+id_start):\n",
    "        first = json.dumps({ \"index\": { \"_index\": index_name, \"_id\": str(i+before_import) } }, ensure_ascii=False) + \"\\n\"\n",
    "        second = json.dumps({\"metadata\": {\"source\": str(df.iloc[i-id_start, 0]),\n",
    "                                          \"page\": i,\n",
    "                                         },\n",
    "                             \"image_base64\": str(df.iloc[i-id_start, 3]),\n",
    "                             \"paragraph\": str(df.iloc[i-id_start, 1]),\n",
    "                             \"sentence\": str(df.iloc[i-id_start, 2]),\n",
    "                             \"sentence_vector\": json.loads(df.iloc[i-id_start, 4])},\n",
    "                            ensure_ascii=False) + \"\\n\"\n",
    "        payloads += first + second\n",
    "    # print(payloads)\n",
    "    r = requests.post(url, auth=awsauth, headers=headers, data=payloads.encode()) # requests.get, post, and delete have similar syntax\n",
    "    # print(r.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9130dc2-88ae-41d6-836c-dc157365d98b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#==============Main Preprocess Data and Import===============\n",
    "\n",
    "slice = 1\n",
    "df_all = []\n",
    "names = os.listdir(folder_path)\n",
    "print(folder_path)\n",
    "# before_import = 0\n",
    "failed_files = []\n",
    "for j in range(len(names)):\n",
    "    name = names[j]\n",
    "    print(name)\n",
    "    if name[0] == '.':\n",
    "        continue\n",
    "#     if os.path.splitext(name)[1] not in ['.doc','.docx']:continue\n",
    "    try:\n",
    "        df, _ = read_doc(os.path.join(folder_path, name))\n",
    "        df = embbeding(df)\n",
    "        df_all.append(df)\n",
    "        for i in range(len(df)//slice+1):\n",
    "            import_data(df[slice*i:slice*(i+1)], slice*i, before_import)\n",
    "            print('\\r import %i out of %i finished'%(i, len(df)//slice+1), end='')\n",
    "        before_import += len(df)\n",
    "        print(' file %i out of %i finished'%(j+1, len(names)))\n",
    "    except Exception as ex:\n",
    "#         traceback.print_exc(file=sys.stdout)\n",
    "        failed_files.append(name)\n",
    "        print(f\"=================Exception================={ex}\")\n",
    "print(before_import)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
